import boto3
import pandas as pd
import requests
from datetime import datetime
from functools import lru_cache

@lru_cache(maxsize=None)
def buscar_dados_dia_cached(cidade, data_str, api_key):
    url = f"http://api.weatherapi.com/v1/history.json?key={api_key}&q={cidade}&dt={data_str}&lang=pt"
    response = requests.get(url)

    if response.status_code != 200:
        print(f"Erro API: {response.status_code}")
        return None

    return response.json()

def pegar_temperatura_historica(cidade, datahora, api_key):
    data_str = datahora.strftime('%Y-%m-%d')
    hora_alvo = datahora.hour

    dados = buscar_dados_dia_cached(cidade, data_str, api_key)
    if dados is None:
        return None

    try:
        horas = dados['forecast']['forecastday'][0]['hour']
        for hora in horas:
            if int(hora['time'].split(' ')[1].split(':')[0]) == hora_alvo:
                return hora['temp_c']
    except Exception as e:
        print(f"Erro ao processar dados: {e}")

    return None

bucket_name = 'client-bucket-381492149341'
cidade = "São Paulo"
api_key = "0cce56c4181643569e400824252905"

s3 = boto3.client('s3')
response = s3.list_objects_v2(Bucket=bucket_name)

if 'Contents' in response:
    csv_files = [obj for obj in response['Contents'] if obj['Key'].endswith('.csv')]
    if csv_files:
        latest_file = sorted(csv_files, key=lambda x: x['LastModified'], reverse=True)[0]
        latest_key = latest_file['Key']
        print(f"Último arquivo CSV: {latest_key}")

        obj = s3.get_object(Bucket=bucket_name, Key=latest_key)
        df = pd.read_csv(obj['Body'])

        df['data_captura'] = pd.to_datetime(df['data_captura'])

        df['temperatura'] = df['data_captura'].apply(
            lambda dt: pegar_temperatura_historica(cidade, dt, api_key)
        )

        print(df.head(20))
    else:
        print("Nenhum CSV encontrado no bucket.")
else:
    print("Bucket vazio.")


#pip install boto3 pandas requests "urllib3<2"
